name: system-sanity-check

env:
  CUSTOMER: ${{ secrets.CUSTOMER }}
  USERNAME: ${{ secrets.USERNAME }}
  PASSWORD: ${{ secrets.PASSWORD }}
  CLIENT_ID: ${{ secrets.CLIENT_ID_PROD }}
  SECRET_KEY: ${{ secrets.SECRET_KEY_PROD }}
  REGISTRY_USERNAME: ${{ secrets.REGISTRY_USERNAME }}
  REGISTRY_PASSWORD: ${{ secrets.REGISTRY_PASSWORD }}

on:
  workflow_call:
      inputs:
        RETRY_JOB:
          required: false
          type: boolean
        BINARY_TESTS:
          type: string
          default: '[ "scan_nsa", 
                      "scan_mitre", 
                      "scan_with_exceptions", 
                      "scan_repository", 
                      "scan_local_file", 
                      "scan_local_glob_files", 
                      "scan_local_list_of_files", 
                      "scan_nsa_and_submit_to_backend", 
                      "scan_mitre_and_submit_to_backend", 
                      "scan_local_repository_and_submit_to_backend", 
                      "scan_repository_from_url_and_submit_to_backend", 
                      "scan_with_exception_to_backend", 
                      "scan_with_custom_framework", 
                      "scan_customer_configuration", 
                      "host_scanner"
                    ]'
  
jobs:
  wf-preparation:
    name: secret-validator
    runs-on: ubuntu-latest
    outputs:
      TEST_NAMES: ${{ steps.export_tests_to_env.outputs.TEST_NAMES }}
      is-secret-set: ${{ steps.check-secret-set.outputs.is-secret-set }}
    steps:
      - name: check if the necessary secrets are set in GitHub secrets
        id: check-secret-set
        run: |
          echo "is-secret-set=${{ env.CUSTOMER != '' && 
                                    env.USERNAME != '' && 
                                    env.PASSWORD != '' && 
                                    env.CLIENT_ID != '' && 
                                    env.SECRET_KEY != '' && 
                                    env.REGISTRY_USERNAME != '' && 
                                    env.REGISTRY_PASSWORD != '' }}" >> $GITHUB_OUTPUT

      - id: export_tests_to_env
        name: set test name
        run: |
          echo "TEST_NAMES=$input" >> $GITHUB_OUTPUT
        env:
          input: ${{ inputs.BINARY_TESTS }}

  run-tests:
      strategy:
        fail-fast: false    
        matrix:
          TEST: ${{ fromJson(needs.wf-preparation.outputs.TEST_NAMES) }}
          BASE_CONFIG: ["eu","us"]  # Runs for both environments
      needs: wf-preparation
      runs-on: ubuntu-latest
      steps:
        - name: Checkout systests repo
          uses: actions/checkout@v3
          with:
            repository: armosec/system-tests
            path: .

        - uses: actions/setup-python@v4
          timeout-minutes: 10
          with:
            python-version: '3.8.13'
            cache: 'pip' 

        # - name: Create Kind Config
        #   run: |
        #     cat <<EOF > kind-config.yaml
        #     kind: Cluster
        #     apiVersion: kind.x-k8s.io/v1alpha4
        #     networking:
        #       apiServerPort: ${{ matrix.BASE_CONFIG == 'production' && 6443 || 6444 }}  # Unique port for each cluster
        #     EOF

        - name: Generate UUID for Cluster Name
          id: uuid
          run: echo "RANDOM_UUID=${{ matrix.BASE_CONFIG }}-$(uuidgen)" >> $GITHUB_OUTPUT

        - name: Create k8s Kind Cluster
          id: kind-cluster-install
          uses: helm/kind-action@v1.3.0
          with:
            cluster_name: ${{ steps.uuid.outputs.RANDOM_UUID }}
            # config_path: ./kind-config.yaml

        - name: Wait for cluster readiness
          run: sleep 30  # Allows time for the cluster to initialize

        - name: Create Environment
          run: ./create_env.sh  # Sets up necessary environment configurations

        - name: Run Tests
          if: ${{ inputs.RETRY_JOB == false }}
          id: StepId1
          uses: nick-fields/retry@v3
          with:
            timeout_seconds: 600
            retry_wait_seconds: 60
            max_attempts: 2
            retry_on: any
            command: |
              echo "Running tests on ${{ matrix.BASE_CONFIG }}"
              source systests_python_env/bin/activate

              # Set the environment argument based on BASE_CONFIG
              if [[ "${{ matrix.BASE_CONFIG }}" == "eu" ]]; then
                ENVIRONMENT="production"
              elif [[ "${{ matrix.BASE_CONFIG }}" == "us" ]]; then
                ENVIRONMENT="production-us"
              fi
              
              python3 systest-cli.py \
                -t ${{ matrix.TEST }} \
                -b $ENVIRONMENT \
                --logger DEBUG \
                --kwargs helm_branch=release
              deactivate

        - name: Run Tests Repeated
          if: ${{ inputs.RETRY_JOB == true }}
          id: StepId2
          run: |
            echo "Running repeated tests on ${{ matrix.BASE_CONFIG }}"
            source systests_python_env/bin/activate
            while true; do
              timestamp=$(date +"%Y-%m-%d %H:%M:%S")
              echo "$timestamp,0" >> ~/sanity_logs.csv

              # Set the environment argument based on BASE_CONFIG
              if [[ "${{ matrix.BASE_CONFIG }}" == "eu" ]]; then
                ENVIRONMENT="production"
              elif [[ "${{ matrix.BASE_CONFIG }}" == "us" ]]; then
                ENVIRONMENT="production-us"
              fi

              python3 systest-cli.py \
                -t ${{ matrix.TEST }} \
                -b $ENVIRONMENT \
                --logger DEBUG \
                --kwargs helm_branch=release
              deactivate

              if [ $? = 0 ]; then
                timestamp=$(date +"%Y-%m-%d %H:%M:%S")
                echo "$timestamp,1" >> ~/sanity_logs.csv
                break
              fi
              sleep 60
            done

        - uses: actions/checkout@v3

        - name: Append to CSV if Pass
          if: steps.StepId1.outcome == 'success'
          run: |
            timestamp=$(date +"%Y-%m-%d %H:%M:%S")
            echo "$timestamp,1" >> ~/sanity_logs.csv
            eval sed\ s/\$/\\$'\n'/g\ ~/sanity_logs.csv | cat >> "logs/sanity_logs.csv"

        - name: Append to CSV if Failed 
          if: steps.StepId2.outcome == 'success'
          run: |
            eval sed\ s/\$/\\$'\n'/g\ ~/sanity_logs.csv | cat >> "logs/sanity_logs.csv"

        - name: Commit Changes
          uses: EndBug/add-and-commit@v9
          continue-on-error: true
          with:
            message: "Update sanity logs with new data"
            author_name: bvolovat
            author_email: borisv@armosec.io
            commit: --signoff
            pull: '--ff-only'
            add: ./logs/*

        - name: Test Report
          uses: mikepenz/action-junit-report@v3.6.1
          if: always()
          with:
            report_paths: '**/results_xml_format/**.xml'
